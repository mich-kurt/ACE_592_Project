{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\zalian2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zalian2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "string.punctuation\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import nltk\n",
    "from wordcloud import WordCloud\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "\n",
    "# Download the stopwords resource\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = \"C:/Users/zalian2/OneDrive - University of Illinois - Urbana/UIUC/Spring 2024/ACE 592 SAE/ACE_592_Project/Data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading in the raw data\n",
    "df = pd.read_csv(dir_+\"raw_drug_reviews.csv\")\n",
    "# df = pd.read_csv(dir_+\"drug_reviews_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some rows had strange characters. Creating this function to clean the text\n",
    "import re\n",
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z0-9\\s.,!?\\'\":;()]', '', text)\n",
    "\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
    "\n",
    "    cleaned_text = cleaned_text.strip()\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_review'] = df['Text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(dir_ + \"updated_drug_reviews_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I want to 'trim' the the text columns. For example if the value for the drug column is 'Tirzepatide ', I want it to be 'Tirzepatide'\n",
    "df[['Text', 'Drug', 'cleaned_review']] = df[['Text', 'Drug', 'cleaned_review']].apply(lambda x: x.str.strip())\n",
    "df = df.rename(columns={'cleaned_review': 'Comment'})\n",
    "# Make the text lowercase\n",
    "df['lower_text'] =  df['Comment'].str.lower()\n",
    "remv_punc = str.maketrans('','',string.punctuation + '“' +\"‘\"+'”')\n",
    "# Remove the punctuation\n",
    "df['lower_text_NoPunct'] = df['lower_text'].str.translate(remv_punc)\n",
    "\n",
    "# Download the stopwords, but add another list with \"amp\", \"\", and white space \" \"\n",
    "sw_list = stopwords.words('english') + ['amp','',\" \"]\n",
    "# split on whitespace to get separate words\n",
    "df['words'] = [x.split(\" \") for x in df['lower_text_NoPunct']]\n",
    "# Take out stopwords\n",
    "# Convert the text to a set, subtract the set of stopwords, turn into list\n",
    "df['words'] = [list(set(x) - set(sw_list)) for x in df['words']]\n",
    "# Creating an instance of the CountVectorizer with a stop word list.\n",
    "vct = CountVectorizer(stop_words=sw_list)\n",
    "# Gives me an output of word counts \n",
    "X = vct.fit_transform(list(df['lower_text_NoPunct']))\n",
    "# make X a dataframe\n",
    "word_counts = pd.DataFrame(X.sum(axis=0))\n",
    "# Assign to columns a list of the feature names from .get_feature_names_out()\n",
    "word_counts.columns = vct.get_feature_names_out()\n",
    "# Transpose, so that word labels are rows instead of columns\n",
    "word_counts = word_counts.T\n",
    "words =  word_counts[0].index\n",
    "# word_counts.reset_index(inplace=True)\n",
    "# word_counts.rename(columns = {'index' : 'Words', 0 : 'Count'}, inplace=True)\n",
    "# word_counts = word_counts.pivot_table(index=None, columns='Words', values='Count', aggfunc='first', fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## word pairs\n",
    "## Creating another column that produces a list of words for each review \n",
    "df['words_orig'] = [x.split(\" \") for x in df['lower_text_NoPunct']]\n",
    "## The function below creates a list of all consecutive words in a string. I found it on Stackoverflow\n",
    "from itertools import islice\n",
    "\n",
    "## k is the number of consecutive elements\n",
    "def consecutive_k_elements_join(lst, k):\n",
    "    return [' '.join(x) for x in zip(*(islice(lst, i, None) for i in range(k)))]\n",
    "## Applying the function to all rows\n",
    "df['words_pairs'] = df.apply(lambda x: consecutive_k_elements_join(x['words_orig'],2), axis=1)\n",
    "## Then, I want to add the word-pairs as columns in our 'data' dataset\n",
    "## Adding an argument to the CountVectorizer function to get count of pairwise words\n",
    "vct = CountVectorizer(stop_words=sw_list, ngram_range=(2, 2))\n",
    "# Gives me an output of word counts \n",
    "X2 = vct.fit_transform(df['lower_text_NoPunct'])\n",
    "# make X a dataframe\n",
    "wordpairs_counts = pd.DataFrame(X2.sum(axis=0))\n",
    "# Assign to columns a list of the feature names from .get_feature_names_out()\n",
    "wordpairs_counts.columns = vct.get_feature_names_out()\n",
    "# Transpose, so that word labels are rows instead of columns\n",
    "wordpairs_counts = wordpairs_counts.T\n",
    "wordpairs =  wordpairs_counts[0].index\n",
    "\n",
    "words = words.to_list() + wordpairs.to_list() \n",
    "\n",
    "data = pd.DataFrame(X.toarray(), \\\n",
    "                 columns=word_counts.index)\n",
    "\n",
    "## Concatenating the columns of the word pairs\n",
    "data_pair=pd.concat([data, pd.DataFrame(X2.toarray(),columns=wordpairs_counts.index)], axis=1)\n",
    "# merge pair words with words\n",
    "data = pd.concat([data,data_pair],axis=1)\n",
    "\n",
    "# data['Rating'] = df['Rating'].to_list()\n",
    "# data['Drug'] = df['Drug'].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>01032020</th>\n",
       "      <th>011723</th>\n",
       "      <th>02</th>\n",
       "      <th>025</th>\n",
       "      <th>025mg</th>\n",
       "      <th>03</th>\n",
       "      <th>05</th>\n",
       "      <th>050</th>\n",
       "      <th>05mg</th>\n",
       "      <th>06</th>\n",
       "      <th>...</th>\n",
       "      <th>zofran stomach</th>\n",
       "      <th>zofran told</th>\n",
       "      <th>zofran took</th>\n",
       "      <th>zofran tuesday</th>\n",
       "      <th>zombie described</th>\n",
       "      <th>zombie hours</th>\n",
       "      <th>zombie looked</th>\n",
       "      <th>zombie worst</th>\n",
       "      <th>zone 1st</th>\n",
       "      <th>zone glucometer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 38444 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     01032020  011723  02  025  025mg  03  05  050  05mg  06  ...  \\\n",
       "0           0       0   0    0      0   0   0    0     0   0  ...   \n",
       "1           0       0   0    0      0   0   0    0     0   0  ...   \n",
       "2           0       0   0    0      0   0   0    0     0   0  ...   \n",
       "3           0       0   0    1      0   0   1    0     0   0  ...   \n",
       "4           0       0   0    0      0   0   0    0     0   0  ...   \n",
       "..        ...     ...  ..  ...    ...  ..  ..  ...   ...  ..  ...   \n",
       "745         0       0   0    0      0   0   0    0     0   0  ...   \n",
       "746         0       0   0    0      0   0   0    0     0   0  ...   \n",
       "747         0       0   0    0      0   0   0    0     0   0  ...   \n",
       "748         0       0   0    0      0   0   0    0     0   0  ...   \n",
       "749         0       0   0    0      0   0   0    0     0   0  ...   \n",
       "\n",
       "     zofran stomach  zofran told  zofran took  zofran tuesday  \\\n",
       "0                 0            0            0               0   \n",
       "1                 0            0            0               0   \n",
       "2                 0            0            0               0   \n",
       "3                 0            0            0               0   \n",
       "4                 0            0            0               0   \n",
       "..              ...          ...          ...             ...   \n",
       "745               0            0            0               0   \n",
       "746               0            0            0               0   \n",
       "747               0            0            0               0   \n",
       "748               0            0            0               0   \n",
       "749               0            0            0               0   \n",
       "\n",
       "     zombie described  zombie hours  zombie looked  zombie worst  zone 1st  \\\n",
       "0                   0             0              0             0         0   \n",
       "1                   0             0              0             0         0   \n",
       "2                   0             0              0             0         0   \n",
       "3                   0             0              0             0         0   \n",
       "4                   0             0              0             0         0   \n",
       "..                ...           ...            ...           ...       ...   \n",
       "745                 0             0              0             0         0   \n",
       "746                 1             0              0             0         0   \n",
       "747                 0             0              0             0         0   \n",
       "748                 0             0              0             0         0   \n",
       "749                 0             0              0             0         0   \n",
       "\n",
       "     zone glucometer  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "..               ...  \n",
       "745                0  \n",
       "746                0  \n",
       "747                0  \n",
       "748                0  \n",
       "749                0  \n",
       "\n",
       "[750 rows x 38444 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "## Creating a column for sentiment scores in the original dataset\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "df['sentiment'] = [sid.polarity_scores(x)['compound'] for x in df.Comment]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Comment</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>lower_text_NoPunct</th>\n",
       "      <th>words</th>\n",
       "      <th>words_orig</th>\n",
       "      <th>words_pairs</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I started ozempic 9 months ago. At the time I ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Ozempic</td>\n",
       "      <td>I started ozempic 9 months ago. At the time I ...</td>\n",
       "      <td>i started ozempic 9 months ago. at the time i ...</td>\n",
       "      <td>i started ozempic 9 months ago at the time i w...</td>\n",
       "      <td>[havent, started, 56, suddenly, pleased, ozemp...</td>\n",
       "      <td>[i, started, ozempic, 9, months, ago, at, the,...</td>\n",
       "      <td>[i started, started ozempic, ozempic 9, 9 mont...</td>\n",
       "      <td>0.9453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I did one injection and have been ill since.\\n...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ozempic</td>\n",
       "      <td>I did one injection and have been ill since. H...</td>\n",
       "      <td>i did one injection and have been ill since. h...</td>\n",
       "      <td>i did one injection and have been ill since ha...</td>\n",
       "      <td>[eat, vomiting, since, dizziness, meals, 5, wo...</td>\n",
       "      <td>[i, did, one, injection, and, have, been, ill,...</td>\n",
       "      <td>[i did, did one, one injection, injection and,...</td>\n",
       "      <td>-0.7227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I’ve been Ozempic for 4 weeks.  I am so glad t...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Ozempic</td>\n",
       "      <td>Ive been Ozempic for 4 weeks. I am so glad tha...</td>\n",
       "      <td>ive been ozempic for 4 weeks. i am so glad tha...</td>\n",
       "      <td>ive been ozempic for 4 weeks i am so glad that...</td>\n",
       "      <td>[told, eat, body, 18, weight, sick, smaller, p...</td>\n",
       "      <td>[ive, been, ozempic, for, 4, weeks, i, am, so,...</td>\n",
       "      <td>[ive been, been ozempic, ozempic for, for 4, 4...</td>\n",
       "      <td>0.7257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Started on Ozempic Sept 2020, starting weight ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Ozempic</td>\n",
       "      <td>Started on Ozempic Sept 2020, starting weight ...</td>\n",
       "      <td>started on ozempic sept 2020, starting weight ...</td>\n",
       "      <td>started on ozempic sept 2020 starting weight 3...</td>\n",
       "      <td>[eat, although, hba1c, could, cramps, started,...</td>\n",
       "      <td>[started, on, ozempic, sept, 2020, starting, w...</td>\n",
       "      <td>[started on, on ozempic, ozempic sept, sept 20...</td>\n",
       "      <td>-0.9359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I took one Ozempic injection at .25 and ended ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ozempic</td>\n",
       "      <td>I took one Ozempic injection at .25 and ended ...</td>\n",
       "      <td>i took one ozempic injection at .25 and ended ...</td>\n",
       "      <td>i took one ozempic injection at 25 and ended u...</td>\n",
       "      <td>[unstoppable, soon, please, vomiting, 2, dont,...</td>\n",
       "      <td>[i, took, one, ozempic, injection, at, 25, and...</td>\n",
       "      <td>[i took, took one, one ozempic, ozempic inject...</td>\n",
       "      <td>0.6931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>I have been on Jardiance for 2 years, as my do...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Jardiance</td>\n",
       "      <td>I have been on Jardiance for 2 years, as my do...</td>\n",
       "      <td>i have been on jardiance for 2 years, as my do...</td>\n",
       "      <td>i have been on jardiance for 2 years as my doc...</td>\n",
       "      <td>[years, 2, dont, weight, 63, 8, 58, done, past...</td>\n",
       "      <td>[i, have, been, on, jardiance, for, 2, years, ...</td>\n",
       "      <td>[i have, have been, been on, on jardiance, jar...</td>\n",
       "      <td>0.7535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>I get it everyone is different but I will shar...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Jardiance</td>\n",
       "      <td>I get it everyone is different but I will shar...</td>\n",
       "      <td>i get it everyone is different but i will shar...</td>\n",
       "      <td>i get it everyone is different but i will shar...</td>\n",
       "      <td>[gave, body, pre, minute, causing, blood, suga...</td>\n",
       "      <td>[i, get, it, everyone, is, different, but, i, ...</td>\n",
       "      <td>[i get, get it, it everyone, everyone is, is d...</td>\n",
       "      <td>0.2475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>Disgusting experience. Urinating one and a hal...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Jardiance</td>\n",
       "      <td>Disgusting experience. Urinating one and a hal...</td>\n",
       "      <td>disgusting experience. urinating one and a hal...</td>\n",
       "      <td>disgusting experience urinating one and a half...</td>\n",
       "      <td>[2, dont, ear, half, sore, drug, eye, pain, he...</td>\n",
       "      <td>[disgusting, experience, urinating, one, and, ...</td>\n",
       "      <td>[disgusting experience, experience urinating, ...</td>\n",
       "      <td>-0.8558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>I've been on Jardiance in combination with met...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jardiance</td>\n",
       "      <td>I've been on Jardiance in combination with met...</td>\n",
       "      <td>i've been on jardiance in combination with met...</td>\n",
       "      <td>ive been on jardiance in combination with metf...</td>\n",
       "      <td>[years, besides, 63, lost, infections, also, i...</td>\n",
       "      <td>[ive, been, on, jardiance, in, combination, wi...</td>\n",
       "      <td>[ive been, been on, on jardiance, jardiance in...</td>\n",
       "      <td>-0.4394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>I have taken Jardiance for a little over a yea...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Jardiance</td>\n",
       "      <td>I have taken Jardiance for a little over a yea...</td>\n",
       "      <td>i have taken jardiance for a little over a yea...</td>\n",
       "      <td>i have taken jardiance for a little over a yea...</td>\n",
       "      <td>[antibiotic, urine, hour, year, constant, trac...</td>\n",
       "      <td>[i, have, taken, jardiance, for, a, little, ov...</td>\n",
       "      <td>[i have, have taken, taken jardiance, jardianc...</td>\n",
       "      <td>-0.7440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text  Rating       Drug  \\\n",
       "0    I started ozempic 9 months ago. At the time I ...    10.0    Ozempic   \n",
       "1    I did one injection and have been ill since.\\n...     1.0    Ozempic   \n",
       "2    I’ve been Ozempic for 4 weeks.  I am so glad t...    10.0    Ozempic   \n",
       "3    Started on Ozempic Sept 2020, starting weight ...    10.0    Ozempic   \n",
       "4    I took one Ozempic injection at .25 and ended ...     1.0    Ozempic   \n",
       "..                                                 ...     ...        ...   \n",
       "745  I have been on Jardiance for 2 years, as my do...     1.0  Jardiance   \n",
       "746  I get it everyone is different but I will shar...     1.0  Jardiance   \n",
       "747  Disgusting experience. Urinating one and a hal...     3.0  Jardiance   \n",
       "748  I've been on Jardiance in combination with met...     NaN  Jardiance   \n",
       "749  I have taken Jardiance for a little over a yea...     3.0  Jardiance   \n",
       "\n",
       "                                               Comment  \\\n",
       "0    I started ozempic 9 months ago. At the time I ...   \n",
       "1    I did one injection and have been ill since. H...   \n",
       "2    Ive been Ozempic for 4 weeks. I am so glad tha...   \n",
       "3    Started on Ozempic Sept 2020, starting weight ...   \n",
       "4    I took one Ozempic injection at .25 and ended ...   \n",
       "..                                                 ...   \n",
       "745  I have been on Jardiance for 2 years, as my do...   \n",
       "746  I get it everyone is different but I will shar...   \n",
       "747  Disgusting experience. Urinating one and a hal...   \n",
       "748  I've been on Jardiance in combination with met...   \n",
       "749  I have taken Jardiance for a little over a yea...   \n",
       "\n",
       "                                            lower_text  \\\n",
       "0    i started ozempic 9 months ago. at the time i ...   \n",
       "1    i did one injection and have been ill since. h...   \n",
       "2    ive been ozempic for 4 weeks. i am so glad tha...   \n",
       "3    started on ozempic sept 2020, starting weight ...   \n",
       "4    i took one ozempic injection at .25 and ended ...   \n",
       "..                                                 ...   \n",
       "745  i have been on jardiance for 2 years, as my do...   \n",
       "746  i get it everyone is different but i will shar...   \n",
       "747  disgusting experience. urinating one and a hal...   \n",
       "748  i've been on jardiance in combination with met...   \n",
       "749  i have taken jardiance for a little over a yea...   \n",
       "\n",
       "                                    lower_text_NoPunct  \\\n",
       "0    i started ozempic 9 months ago at the time i w...   \n",
       "1    i did one injection and have been ill since ha...   \n",
       "2    ive been ozempic for 4 weeks i am so glad that...   \n",
       "3    started on ozempic sept 2020 starting weight 3...   \n",
       "4    i took one ozempic injection at 25 and ended u...   \n",
       "..                                                 ...   \n",
       "745  i have been on jardiance for 2 years as my doc...   \n",
       "746  i get it everyone is different but i will shar...   \n",
       "747  disgusting experience urinating one and a half...   \n",
       "748  ive been on jardiance in combination with metf...   \n",
       "749  i have taken jardiance for a little over a yea...   \n",
       "\n",
       "                                                 words  \\\n",
       "0    [havent, started, 56, suddenly, pleased, ozemp...   \n",
       "1    [eat, vomiting, since, dizziness, meals, 5, wo...   \n",
       "2    [told, eat, body, 18, weight, sick, smaller, p...   \n",
       "3    [eat, although, hba1c, could, cramps, started,...   \n",
       "4    [unstoppable, soon, please, vomiting, 2, dont,...   \n",
       "..                                                 ...   \n",
       "745  [years, 2, dont, weight, 63, 8, 58, done, past...   \n",
       "746  [gave, body, pre, minute, causing, blood, suga...   \n",
       "747  [2, dont, ear, half, sore, drug, eye, pain, he...   \n",
       "748  [years, besides, 63, lost, infections, also, i...   \n",
       "749  [antibiotic, urine, hour, year, constant, trac...   \n",
       "\n",
       "                                            words_orig  \\\n",
       "0    [i, started, ozempic, 9, months, ago, at, the,...   \n",
       "1    [i, did, one, injection, and, have, been, ill,...   \n",
       "2    [ive, been, ozempic, for, 4, weeks, i, am, so,...   \n",
       "3    [started, on, ozempic, sept, 2020, starting, w...   \n",
       "4    [i, took, one, ozempic, injection, at, 25, and...   \n",
       "..                                                 ...   \n",
       "745  [i, have, been, on, jardiance, for, 2, years, ...   \n",
       "746  [i, get, it, everyone, is, different, but, i, ...   \n",
       "747  [disgusting, experience, urinating, one, and, ...   \n",
       "748  [ive, been, on, jardiance, in, combination, wi...   \n",
       "749  [i, have, taken, jardiance, for, a, little, ov...   \n",
       "\n",
       "                                           words_pairs  sentiment  \n",
       "0    [i started, started ozempic, ozempic 9, 9 mont...     0.9453  \n",
       "1    [i did, did one, one injection, injection and,...    -0.7227  \n",
       "2    [ive been, been ozempic, ozempic for, for 4, 4...     0.7257  \n",
       "3    [started on, on ozempic, ozempic sept, sept 20...    -0.9359  \n",
       "4    [i took, took one, one ozempic, ozempic inject...     0.6931  \n",
       "..                                                 ...        ...  \n",
       "745  [i have, have been, been on, on jardiance, jar...     0.7535  \n",
       "746  [i get, get it, it everyone, everyone is, is d...     0.2475  \n",
       "747  [disgusting experience, experience urinating, ...    -0.8558  \n",
       "748  [ive been, been on, on jardiance, jardiance in...    -0.4394  \n",
       "749  [i have, have taken, taken jardiance, jardianc...    -0.7440  \n",
       "\n",
       "[750 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
